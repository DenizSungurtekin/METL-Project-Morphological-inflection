{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importation of libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from keras.models import Model,Sequential\n",
    "from keras.layers import Input, LSTM, Dense, SimpleRNN, Embedding\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import copy as c\n",
    "\n",
    "# Input() is used to instantiate a Keras tensor.\n",
    "# Dense implements the operation: output = activation(dot(input, kernel) + bias) \n",
    "# LSTM : Seq to Seq model \n",
    "# Model groups layers into an object with training and inference features \n",
    "\n",
    "# from keras.preprocessing.text import one_hot\n",
    "# from keras.preprocessing.text import text_to_word_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization And Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "\n",
    "fname_train = \"data/finnish-task1-train\"\n",
    "fname_test = \"data/finnish-task1-test\"\n",
    "fname_dev = \"data/finnish-task1-dev\"\n",
    "\n",
    "dataset_train = np.loadtxt(fname_train,dtype = str)\n",
    "dataset_test = np.loadtxt(fname_test,dtype = str)\n",
    "dataset_dev = np.loadtxt(fname_dev,dtype = str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Ã¤Ã¤kkÃ¶stÃ¤Ã¤' 'pos=V,polar=POS,mood=IMP,tense=PRS,per=3,num=SG'\n",
      "  'Ã¤Ã¤kkÃ¶stÃ¤kÃ¶Ã¶n']\n",
      " ['Ã¤Ã¤kkÃ¶stÃ¤Ã¤' 'pos=V,voice=ACT,aspect=PROSP'\n",
      "  'Ã¤Ã¤kkÃ¶stÃ¤mÃ¤isillÃ¤Ã¤n']\n",
      " ['aalloittaisuus' 'pos=N,case=ON+ESS,num=PL' 'aalloittaisuuksilla']\n",
      " ...\n",
      " ['zoonoosi' 'pos=N,case=PRIV,num=SG' 'zoonoositta']\n",
      " ['zsaari' 'pos=N,case=IN+LAT,num=PL' 'zsaareihin']\n",
      " ['zumbata' 'pos=V,polar=POS,mood=POT,tense=PRS,per=2,num=PL'\n",
      "  'zumbannette']]\n",
      "(12693, 3)\n"
     ]
    }
   ],
   "source": [
    "print(dataset_train)\n",
    "print(dataset_train.shape)\n",
    "\n",
    "# print(np.where(dataset_ttrain == 'Ã¤Ã¤kkÃ¶stÃ¤Ã¤' )[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['alkeiskoppi' 'pos=N,case=NOM,num=SG' 'alkeiskoppi']\n",
      " ['lenkkitossut' 'pos=N,case=ON+ESS,num=PL' 'lenkkitossuilla']\n",
      " ['baritonitorvi' 'pos=N,case=PRIV,num=SG' 'baritonitorvetta']\n",
      " ...\n",
      " ['katkeroida' 'pos=V,polar=POS,mood=IND,tense=PRS,per=3,num=SG'\n",
      "  'katkeroi']\n",
      " ['paarmalintu' 'pos=N,case=TRANS,num=PL' 'paarmalinnuiksi']\n",
      " ['malisiÃ¶Ã¶si' 'pos=ADJ,case=IN+ABL,num=SG' 'malisiÃ¶Ã¶sistÃ¤']]\n",
      "(23633, 3)\n"
     ]
    }
   ],
   "source": [
    "print(dataset_test)\n",
    "print(dataset_test.shape)\n",
    "# print(np.where(test == 'Ã¤Ã¤kkÃ¶stÃ¤Ã¤' )[0])\n",
    "# print(test[21533])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['aakkosto' 'pos=N,case=NOM,num=PL' 'aakkostot']\n",
      " ['aallottaa' 'pos=V,mood=PURP,voice=ACT' 'aallottaakseen']\n",
      " ['aaltoluku' 'pos=N,case=FRML,num=SG' 'aaltolukuna']\n",
      " ...\n",
      " ['ystÃ¤vÃ¤piiri' 'pos=N,case=ON+ABL,num=SG' 'ystÃ¤vÃ¤piiriltÃ¤']\n",
      " ['ytimekÃ¤s' 'pos=ADJ,case=ACC,num=SG' 'ytimekkÃ¤Ã¤n']\n",
      " ['zombi' 'pos=N,case=IN+ABL,num=PL' 'zombeista']]\n",
      "(1598, 3)\n"
     ]
    }
   ],
   "source": [
    "print(dataset_dev)\n",
    "print(dataset_dev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Definition of encoding functions\n",
    "\n",
    "# Return the dictionary for a given list\n",
    "def list_to_dict(data):  \n",
    "    dic = {}\n",
    "    for x in data:\n",
    "        dic[x] = dic.get(x, len(dic))\n",
    "    return dic\n",
    "\n",
    "# Return the encoded array\n",
    "def encode(data):\n",
    "    dics = []\n",
    "    for i in range(data.shape[1]):\n",
    "        dic = list_to_dict(data[:,i])\n",
    "        dics.append(dic)\n",
    "        for j in range(len(data[:,i])):\n",
    "            data[:,i][j] = dic[data[:,i][j]]\n",
    "            \n",
    "    return data.astype(np.int),dics\n",
    "\n",
    "# def concatenate(data):\n",
    "#     return np.transpose(np.asarray([np.core.defchararray.add(data[:,0], data[:,1]),data[:,0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding \n",
    "train,dics_train = encode(dataset_train) \n",
    "# test,dics_test = encode(dataset_ttest)\n",
    "# dev,dics_dev = encode(dataset_tdev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0     0     0]\n",
      " [    0     1     1]\n",
      " [    1     2     2]\n",
      " ...\n",
      " [ 9853    21 12675]\n",
      " [ 9854    24 12676]\n",
      " [ 9855    43 12677]]\n",
      "(12693, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train)\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train[:,0:2]\n",
    "y_train = train[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0]\n",
      " [   0    1]\n",
      " [   1    2]\n",
      " ...\n",
      " [9853   21]\n",
      " [9854   24]\n",
      " [9855   43]]\n",
      "(12693, 2)\n"
     ]
    }
   ],
   "source": [
    "print(x_train)\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0     1     2 ... 12675 12676 12677]\n",
      "(12693,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Whenever we’re working with categorical data, we don’t want to leave it as integers because the model will interpreted the samples with a higher number as having more significance. to_categorical is quick and dirty way of encoding the data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = to_categorical(train)\n",
    "# x_test = to_categorical(test)\n",
    "# x_dev = to_categorical(dev)\n",
    "\n",
    "# y_train = to_categorical(train)\n",
    "# y_test = to_categorical(test)\n",
    "# y_dev = to_categorical(dev)\n",
    "\n",
    "# print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define meta-parameter\n",
    "\n",
    "epochs = 30\n",
    "batch_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the encoding dictionaries (word-context-target)\n",
    "\n",
    "def update_dics(data,dics):\n",
    "    new_dics = []\n",
    "    for i in range((data.shape[1])):\n",
    "        dic = dics[i]\n",
    "        for el in data[:,i]:\n",
    "            if el not in list(dic.keys()): \n",
    "                dic[el] = max(list(dic.values())) + 1 # add word to dictionary\n",
    "                \n",
    "        new_dics.append(dic)\n",
    "        \n",
    "    return new_dics\n",
    "\n",
    "# Encode data with given dictionarries\n",
    "\n",
    "def encode_with_dict(data,dics):\n",
    "    copy = c.deepcopy(data)\n",
    "    for i in range((data.shape[1])):\n",
    "        dic = dics[i]\n",
    "        copy[:,i] = np.asarray([dic[el] for el in data[:,i]]) \n",
    "    return copy.astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update dictionarry\n",
    "dics = update_dics(dataset_test,dics_train)\n",
    "dics = update_dics(dataset_dev,dics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding test and dev\n",
    "test = encode_with_dict(dataset_test,dics)\n",
    "dev = encode_with_dict(dataset_dev,dics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  289    19 12678]\n",
      " [ 9856     2 12679]\n",
      " [ 9857    21 12680]\n",
      " ...\n",
      " [ 3365    35 36272]\n",
      " [18939    41 36273]\n",
      " [14794    88 36274]]\n"
     ]
    }
   ],
   "source": [
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17980     9 36275]\n",
      " [11854    59 36276]\n",
      " [10927    37 36277]\n",
      " ...\n",
      " [19296    14 37848]\n",
      " [ 9841    48 37849]\n",
      " [19297    18 37850]]\n"
     ]
    }
   ],
   "source": [
    "print(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = test[:,0:2]\n",
    "x_dev = dev[:,0:2]\n",
    "y_test = test[:,2]\n",
    "y_dev = dev[:,2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = len(list(dics[0].keys()))    # size of vocabulary\n",
    "max_len =  len(list(dics[-1].keys()))    # lenght of input sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  289    19]\n",
      " [ 9856     2]\n",
      " [ 9857    21]\n",
      " ...\n",
      " [ 3365    35]\n",
      " [18939    41]\n",
      " [14794    88]]\n"
     ]
    }
   ],
   "source": [
    "print(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lstm = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lstm.add(Embedding(input_dim = max_words, output_dim = 100,input_length = 2))\n",
    "# model_lstm.add(SpatialDropout1D(0.3))\n",
    "model_lstm.add(LSTM(100)) #dropout = 0.3,recurrent_dropout = 0.3\n",
    "model_lstm.add(Dense(100, activation = 'relu'))\n",
    "# model_lstm.add(Dropout(0.3))\n",
    "model_lstm.add(Dense(max_len, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lstm.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer='Adam',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\dede\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "12693/12693 [==============================] - 6s 504us/step - loss: 10.5432 - accuracy: 0.0000e+00\n",
      "Epoch 2/30\n",
      "12693/12693 [==============================] - 6s 471us/step - loss: 10.5205 - accuracy: 1.5757e-04\n",
      "Epoch 3/30\n",
      "12693/12693 [==============================] - 6s 464us/step - loss: 10.4093 - accuracy: 7.8784e-05\n",
      "Epoch 4/30\n",
      "12693/12693 [==============================] - 6s 478us/step - loss: 9.8622 - accuracy: 0.0000e+00\n",
      "Epoch 5/30\n",
      "12693/12693 [==============================] - 6s 473us/step - loss: 9.6014 - accuracy: 1.5757e-04\n",
      "Epoch 6/30\n",
      "12693/12693 [==============================] - 6s 463us/step - loss: 9.4896 - accuracy: 1.5757e-04\n",
      "Epoch 7/30\n",
      "12693/12693 [==============================] - 6s 466us/step - loss: 9.3109 - accuracy: 1.5757e-04\n",
      "Epoch 8/30\n",
      "12693/12693 [==============================] - 6s 485us/step - loss: 8.9947 - accuracy: 1.5757e-04\n",
      "Epoch 9/30\n",
      "12693/12693 [==============================] - 6s 479us/step - loss: 8.4626 - accuracy: 1.5757e-04\n",
      "Epoch 10/30\n",
      "12693/12693 [==============================] - 6s 475us/step - loss: 7.8165 - accuracy: 0.0011\n",
      "Epoch 11/30\n",
      "12693/12693 [==============================] - 6s 466us/step - loss: 7.1377 - accuracy: 0.0027\n",
      "Epoch 12/30\n",
      "12693/12693 [==============================] - 6s 465us/step - loss: 6.5302 - accuracy: 0.0061\n",
      "Epoch 13/30\n",
      "12693/12693 [==============================] - 6s 468us/step - loss: 5.9973 - accuracy: 0.0121\n",
      "Epoch 14/30\n",
      "12693/12693 [==============================] - 6s 474us/step - loss: 5.5199 - accuracy: 0.0266\n",
      "Epoch 15/30\n",
      "12693/12693 [==============================] - 6s 472us/step - loss: 5.0821 - accuracy: 0.0454\n",
      "Epoch 16/30\n",
      "12693/12693 [==============================] - 6s 470us/step - loss: 4.6498 - accuracy: 0.0714\n",
      "Epoch 17/30\n",
      "12693/12693 [==============================] - 6s 469us/step - loss: 4.2241 - accuracy: 0.1164\n",
      "Epoch 18/30\n",
      "12693/12693 [==============================] - 6s 486us/step - loss: 3.8032 - accuracy: 0.1602\n",
      "Epoch 19/30\n",
      "12693/12693 [==============================] - 6s 478us/step - loss: 3.4081 - accuracy: 0.2217\n",
      "Epoch 20/30\n",
      "12693/12693 [==============================] - 6s 473us/step - loss: 3.0341 - accuracy: 0.2872\n",
      "Epoch 21/30\n",
      "12693/12693 [==============================] - 6s 478us/step - loss: 2.6783 - accuracy: 0.3626\n",
      "Epoch 22/30\n",
      "12693/12693 [==============================] - 6s 464us/step - loss: 2.3485 - accuracy: 0.4369\n",
      "Epoch 23/30\n",
      "12693/12693 [==============================] - 6s 467us/step - loss: 2.0286 - accuracy: 0.5246\n",
      "Epoch 24/30\n",
      "12693/12693 [==============================] - 6s 478us/step - loss: 1.7393 - accuracy: 0.5988\n",
      "Epoch 25/30\n",
      "12693/12693 [==============================] - 6s 473us/step - loss: 1.4752 - accuracy: 0.6746\n",
      "Epoch 26/30\n",
      "12693/12693 [==============================] - 6s 468us/step - loss: 1.2272 - accuracy: 0.7453\n",
      "Epoch 27/30\n",
      "12693/12693 [==============================] - 6s 471us/step - loss: 1.0046 - accuracy: 0.8047\n",
      "Epoch 28/30\n",
      "12693/12693 [==============================] - 6s 463us/step - loss: 0.8258 - accuracy: 0.8491\n",
      "Epoch 29/30\n",
      "12693/12693 [==============================] - 6s 474us/step - loss: 0.6674 - accuracy: 0.8899\n",
      "Epoch 30/30\n",
      "12693/12693 [==============================] - 6s 471us/step - loss: 0.5181 - accuracy: 0.9263\n"
     ]
    }
   ],
   "source": [
    "history = model_lstm.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs = epochs,\n",
    "    batch_size = batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(data,size = 20):\n",
    "    return np.argmax(model_lstm.predict(data[:size]),axis = 1)\n",
    "\n",
    "\n",
    "# function to return key for any value\n",
    "def get_key(val,my_dict):\n",
    "    for key, value in my_dict.items():\n",
    "         if val == value:\n",
    "             return key\n",
    "    return \"key doesn't exist\"\n",
    "\n",
    "# Return words by specifing the index and the dictionary -> decoding\n",
    "def return_pred(y_pred_index,dic):\n",
    "    return np.asarray([get_key(index,dic) for index in y_pred_index])\n",
    "\n",
    "def acc(y_pred,y):\n",
    "    return np.sum(y == y_pred)/len(y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training acuracy:  0.95\n"
     ]
    }
   ],
   "source": [
    "# Decoding and Compute train accuracy \n",
    "\n",
    "size = 20\n",
    "dic_x = dics[0]\n",
    "dic_y = dics[-1]\n",
    "y_pred_index = prediction(x_train,size = size)\n",
    "y_pred = return_pred(y_pred_index,dic_x)\n",
    "y = return_pred(y_train,dic_x)\n",
    "\n",
    "print(\"Training acuracy: \",acc(y_pred,y[:size]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.clf()\n",
    "# loss = history.history['loss']\n",
    "# val_loss = history.history['val_loss']\n",
    "# epochs = range(1, len(loss) + 1)\n",
    "# plt.plot(epochs, loss, 'g', label='Training loss')\n",
    "# plt.plot(epochs, val_loss, 'y', label='Validation loss')\n",
    "# plt.title('Training and validation loss')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0]\n",
      " [   0    1]\n",
      " [   1    2]\n",
      " ...\n",
      " [9853   21]\n",
      " [9854   24]\n",
      " [9855   43]]\n",
      "[[  289    19]\n",
      " [ 9856     2]\n",
      " [ 9857    21]\n",
      " ...\n",
      " [ 3365    35]\n",
      " [18939    41]\n",
      " [14794    88]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train)\n",
    "print(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acuracy:  0.0\n"
     ]
    }
   ],
   "source": [
    "# Decoding and Compute test accuracy \n",
    "\n",
    "size = 20\n",
    "dic_x = dics[0]\n",
    "dic_y = dics[-1]\n",
    "y_pred_index = prediction(x_test,size)\n",
    "y_pred = return_pred(y_pred_index,dic_x)\n",
    "y = return_pred(y_test,dic_x)\n",
    "\n",
    "print(\"Test acuracy: \",acc(y_pred,y[:size]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(y.tolist().count(\"key doesn't exist\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23633\n"
     ]
    }
   ],
   "source": [
    "print(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
