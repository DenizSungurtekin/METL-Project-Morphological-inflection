{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ICTrmW_cgVzi"
   },
   "source": [
    "## Importation of libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "J7fGOSvvgVzl"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from keras.models import Model,Sequential\n",
    "from keras.layers import Input, LSTM, Dense, SimpleRNN, Embedding\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from numpy import array\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import TimeDistributed\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy as cp\n",
    "\n",
    "# Input() is used to instantiate a Keras tensor.\n",
    "# Dense implements the operation: output = activation(dot(input, kernel) + bias) \n",
    "# LSTM : Seq to Seq model \n",
    "# Model groups layers into an object with training and inference features \n",
    "\n",
    "# from keras.preprocessing.text import one_hot\n",
    "# from keras.preprocessing.text import text_to_word_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-WUWRY0NgVzn"
   },
   "source": [
    "## Data Visualization And Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "D0XcJYEbgVzn"
   },
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "\n",
    "fname_train = \"data/finnish-task1-train\"\n",
    "fname_test = \"data/finnish-task1-test\"\n",
    "fname_dev = \"data/finnish-task1-dev\"\n",
    "\n",
    "train = np.loadtxt(fname_train,dtype = str)\n",
    "test = np.loadtxt(fname_test,dtype = str)\n",
    "dev = np.loadtxt(fname_dev,dtype = str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "PHODoLqigVzo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Ã¤Ã¤kkÃ¶stÃ¤Ã¤' 'pos=V,polar=POS,mood=IMP,tense=PRS,per=3,num=SG'\n",
      "  'Ã¤Ã¤kkÃ¶stÃ¤kÃ¶Ã¶n']\n",
      " ['Ã¤Ã¤kkÃ¶stÃ¤Ã¤' 'pos=V,voice=ACT,aspect=PROSP'\n",
      "  'Ã¤Ã¤kkÃ¶stÃ¤mÃ¤isillÃ¤Ã¤n']\n",
      " ['aalloittaisuus' 'pos=N,case=ON+ESS,num=PL' 'aalloittaisuuksilla']\n",
      " ...\n",
      " ['zoonoosi' 'pos=N,case=PRIV,num=SG' 'zoonoositta']\n",
      " ['zsaari' 'pos=N,case=IN+LAT,num=PL' 'zsaareihin']\n",
      " ['zumbata' 'pos=V,polar=POS,mood=POT,tense=PRS,per=2,num=PL'\n",
      "  'zumbannette']]\n",
      "(12693, 3)\n",
      "-----------\n",
      "[['alkeiskoppi' 'pos=N,case=NOM,num=SG' 'alkeiskoppi']\n",
      " ['lenkkitossut' 'pos=N,case=ON+ESS,num=PL' 'lenkkitossuilla']\n",
      " ['baritonitorvi' 'pos=N,case=PRIV,num=SG' 'baritonitorvetta']\n",
      " ...\n",
      " ['katkeroida' 'pos=V,polar=POS,mood=IND,tense=PRS,per=3,num=SG'\n",
      "  'katkeroi']\n",
      " ['paarmalintu' 'pos=N,case=TRANS,num=PL' 'paarmalinnuiksi']\n",
      " ['malisiÃ¶Ã¶si' 'pos=ADJ,case=IN+ABL,num=SG' 'malisiÃ¶Ã¶sistÃ¤']]\n",
      "(23633, 3)\n",
      "-----------\n",
      "[['aakkosto' 'pos=N,case=NOM,num=PL' 'aakkostot']\n",
      " ['aallottaa' 'pos=V,mood=PURP,voice=ACT' 'aallottaakseen']\n",
      " ['aaltoluku' 'pos=N,case=FRML,num=SG' 'aaltolukuna']\n",
      " ...\n",
      " ['ystÃ¤vÃ¤piiri' 'pos=N,case=ON+ABL,num=SG' 'ystÃ¤vÃ¤piiriltÃ¤']\n",
      " ['ytimekÃ¤s' 'pos=ADJ,case=ACC,num=SG' 'ytimekkÃ¤Ã¤n']\n",
      " ['zombi' 'pos=N,case=IN+ABL,num=PL' 'zombeista']]\n",
      "(1598, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train)\n",
    "print(train.shape)\n",
    "print('-----------')\n",
    "print(test)\n",
    "print(test.shape)\n",
    "print('-----------')\n",
    "print(dev)\n",
    "print(dev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "x7Br3-Cql6TM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ã¤Ã¤kkÃ¶stÃ¤Ã¤,pos=V,polar=POS,mood=IMP,tense=PRS,per=3,num=SG', 'Ã¤Ã¤kkÃ¶stÃ¤Ã¤,pos=V,voice=ACT,aspect=PROSP', 'aalloittaisuus,pos=N,case=ON+ESS,num=PL', 'aallokas,pos=ADJ,case=FRML,num=PL', 'aalloppi,pos=N,case=IN+ESS,num=PL', 'aaltoilla,pos=V,polar=POS,mood=COND,tense=PRS,per=1,num=PL', 'aaltoilla,pos=V,polar=POS,mood=IMP,tense=PST,per=2,num=SG', 'aaltoilla,pos=V,polar=POS,mood=POT,tense=PRS,per=3,num=SG', 'aaltomuoto,pos=N,case=PRIV,num=PL', 'aaltopelti,pos=N,case=NOM,num=PL']\n"
     ]
    }
   ],
   "source": [
    "input_train = [ i+','+j for i,j in zip(train[:,0],train[:,1])]\n",
    "output_train = train[:,2]\n",
    "\n",
    "print(input_train[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "sbuj_XYlmuaw"
   },
   "outputs": [],
   "source": [
    "# Input\n",
    "tokenizer_in = Tokenizer()\n",
    "tokenizer_in.fit_on_texts(input_train)\n",
    "encoded_in = tokenizer_in.texts_to_sequences(input_train)\n",
    "word_index_in = tokenizer_in.word_index\n",
    "vocabulary_in = list(word_index_in.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9c5-__J_m1T1"
   },
   "outputs": [],
   "source": [
    "print(\"Vocabulary (Input)\",vocabulary_in)\n",
    "print(\"The word index (Input)\",word_index_in)\n",
    "print(\"Encoded version of the inputs (Input)\",encoded_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "kkRGIj9MnYDM"
   },
   "outputs": [],
   "source": [
    "#Output\n",
    "tokenizer_out = Tokenizer()\n",
    "tokenizer_out.fit_on_texts(output_train)\n",
    "encoded_out = tokenizer_out.texts_to_sequences(output_train)\n",
    "word_index_out = tokenizer_out.word_index\n",
    "vocabulary_out = list(word_index_out.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "lg7qUywloyTg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary (Output) ['antilooppina', 'bio', 'aero', 'aktualisoinnin', 'beeta', 'karoteenit', 'oikeuksissa', 'data', 'erityisnosto', 'oikeuden']\n",
      "The word index (Output) [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "Encoded version of the outputs (Output) [[42], [43], [44], [45], [46], [47], [48], [49], [50], [51]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Vocabulary (Output)\",vocabulary_out[0:10])\n",
    "print(\"The word index (Output)\",list(word_index_out.values())[0:10])\n",
    "print(\"Encoded version of the outputs (Output)\",encoded_out[0:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "0YSCWL6JpCrn"
   },
   "outputs": [],
   "source": [
    "## Padding\n",
    "def padding(seq):\n",
    "  max_len = np.max([len(sentence) for sentence in seq])\n",
    "  return pad_sequences(seq, maxlen = max_len, padding = 'post')\n",
    "\n",
    "\n",
    "## Padding\n",
    "def padding_2(seq,n):\n",
    "  return pad_sequences(seq, maxlen = n, padding = 'post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "zjPuVHDjpLjb"
   },
   "outputs": [],
   "source": [
    "inputs = padding(encoded_in)\n",
    "outputs = padding(encoded_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "WFlrJoSoqTjt"
   },
   "outputs": [],
   "source": [
    "encoder_input_data = to_categorical(inputs, num_classes = len(vocabulary_in) + 1) # input\n",
    "decoder_input_data = to_categorical(outputs, num_classes = len(vocabulary_out) + 1) # output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_target_data = np.zeros(decoder_input_data.shape)\n",
    "for index,data in enumerate(decoder_input_data) : \n",
    "    X = cp.deepcopy(data)\n",
    "    decoder_target_data[index] = np.roll(X,-1,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12693, 13, 9944)\n",
      "(12693, 4, 12738)\n",
      "(12693, 4, 12738)\n"
     ]
    }
   ],
   "source": [
    "print(encoder_input_data.shape)\n",
    "print(decoder_input_data.shape)\n",
    "print(decoder_target_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_data(data):\n",
    "    \n",
    "    inputs = [ i+','+j for i,j in zip(data[:,0],data[:,1])]\n",
    "    outputs = data[:,2]\n",
    "    \n",
    "    # inputs\n",
    "    I_tokenizer_in = Tokenizer()\n",
    "    I_tokenizer_in.fit_on_texts(inputs)\n",
    "    I_encoded_in = tokenizer_in.texts_to_sequences(inputs)\n",
    "    I_word_index_in = tokenizer_in.word_index\n",
    "    I_vocabulary_in = list(I_word_index_in.keys())\n",
    "    \n",
    "    \n",
    "    # outputs   \n",
    "    O_tokenizer_out = Tokenizer()\n",
    "    O_tokenizer_out.fit_on_texts(outputs)\n",
    "    O_encoded_out = tokenizer_out.texts_to_sequences(outputs)\n",
    "    O_word_index_out = tokenizer_out.word_index\n",
    "    O_vocabulary_out = list(O_word_index_out.keys())\n",
    "    \n",
    "    inputs = padding_2(I_encoded_in,13)\n",
    "    outputs = padding_2(O_encoded_out,4)\n",
    "    \n",
    "    _encoder_input_data = to_categorical(inputs, num_classes = len(vocabulary_in) + 1) # input\n",
    "    _decoder_input_data = to_categorical(outputs, num_classes = len(vocabulary_out) + 1) # output\n",
    "    \n",
    "    _decoder_target_data = np.zeros(_decoder_input_data.shape)\n",
    "    for index,data in enumerate(_decoder_input_data): \n",
    "        X = cp.deepcopy(data)\n",
    "        _decoder_target_data[index] = np.roll(X,-1,axis=0)\n",
    "    \n",
    "    return _encoder_input_data,_decoder_input_data,_decoder_target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode test data\n",
    "encoder_input_data_val,decoder_input_data_val,decoder_target_data_val = encode_data(test)\n",
    "\n",
    "# Encode dev data\n",
    "encoder_input_data_val_dev,decoder_input_data_val_dev,decoder_target_data_val_dev = encode_data(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1598, 13, 9944)\n",
      "(1598, 4, 12738)\n",
      "(1598, 4, 12738)\n"
     ]
    }
   ],
   "source": [
    "print(encoder_input_data_val_dev.shape)\n",
    "print(decoder_input_data_val_dev.shape)\n",
    "print(decoder_target_data_val_dev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23633, 13, 9944)\n",
      "(23633, 4, 12738)\n",
      "(23633, 4, 12738)\n"
     ]
    }
   ],
   "source": [
    "print(encoder_input_data_val.shape)\n",
    "print(decoder_input_data_val.shape)\n",
    "print(decoder_target_data_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Encoder Architecture\n",
    "\"\"\"\n",
    "\n",
    "NUM_HIDDEN_UNITS = 256 # NUM_HIDDEN_LAYERS\n",
    "BATCH_SIZE = 500\n",
    "NUM_EPOCHS = 20\n",
    "\n",
    "encoder_vocab_size = len(vocabulary_in) + 1\n",
    "decoder_vocab_size = len(vocabulary_out) + 1\n",
    "\n",
    "encoder_inputs = Input(shape=(None, encoder_vocab_size))\n",
    "encoder_lstm = LSTM(units=NUM_HIDDEN_UNITS, return_state=True)\n",
    "# x-axis: time-step lstm\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
    "encoder_states = [state_h, state_c] # We discard `encoder_outputs` and only keep the states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Decoder Architecture\n",
    "\"\"\"\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_inputs = Input(shape=(None, decoder_vocab_size))\n",
    "decoder_lstm = LSTM(units=NUM_HIDDEN_UNITS, return_sequences=True, return_state=True)\n",
    "# x-axis: time-step lstm\n",
    "decoder_outputs, de_state_h, de_state_c = decoder_lstm(decoder_inputs, initial_state=encoder_states) # Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_softmax_layer = Dense(decoder_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_softmax_layer(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Encoder-Decoder Architecture\n",
    "\"\"\"\n",
    "# Define the model that will turn, `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\",metrics = ['accuracy']) # Set up model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None, 9944)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None, 12738)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 256), (None, 10445824    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, None, 256),  13306880    input_2[0][0]                    \n",
      "                                                                 lstm_1[0][1]                     \n",
      "                                                                 lstm_1[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 12738)  3273666     lstm_2[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 27,026,370\n",
      "Trainable params: 27,026,370\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10154 samples, validate on 2539 samples\n",
      "Epoch 1/20\n",
      "10154/10154 [==============================] - 104s 10ms/step - loss: 4.6259 - accuracy: 0.7116 - val_loss: 3.1712 - val_accuracy: 0.7481\n",
      "Epoch 2/20\n",
      "10154/10154 [==============================] - 66s 6ms/step - loss: 2.8114 - accuracy: 0.7483 - val_loss: 3.0842 - val_accuracy: 0.7481\n",
      "Epoch 3/20\n",
      "10154/10154 [==============================] - 64s 6ms/step - loss: 2.5667 - accuracy: 0.7483 - val_loss: 3.0045 - val_accuracy: 0.7481\n",
      "Epoch 4/20\n",
      "10154/10154 [==============================] - 66s 7ms/step - loss: 2.4652 - accuracy: 0.7483 - val_loss: 3.0488 - val_accuracy: 0.7481\n",
      "Epoch 5/20\n",
      "10154/10154 [==============================] - 64s 6ms/step - loss: 2.4327 - accuracy: 0.7483 - val_loss: 3.1215 - val_accuracy: 0.7481\n",
      "Epoch 6/20\n",
      "10154/10154 [==============================] - 64s 6ms/step - loss: 2.3773 - accuracy: 0.7483 - val_loss: 3.1448 - val_accuracy: 0.7481\n",
      "Epoch 7/20\n",
      "10154/10154 [==============================] - 64s 6ms/step - loss: 2.3661 - accuracy: 0.7483 - val_loss: 3.9835 - val_accuracy: 0.7481\n",
      "Epoch 8/20\n",
      "10154/10154 [==============================] - 64s 6ms/step - loss: 2.3951 - accuracy: 0.7483 - val_loss: 3.1141 - val_accuracy: 0.7481\n",
      "Epoch 9/20\n",
      "10154/10154 [==============================] - 66s 6ms/step - loss: 2.3508 - accuracy: 0.7483 - val_loss: 3.0622 - val_accuracy: 0.7481\n",
      "Epoch 10/20\n",
      "10154/10154 [==============================] - 64s 6ms/step - loss: 2.3480 - accuracy: 0.7483 - val_loss: 3.6121 - val_accuracy: 0.7481\n",
      "Epoch 11/20\n",
      "10154/10154 [==============================] - 64s 6ms/step - loss: 2.3817 - accuracy: 0.7483 - val_loss: 3.0001 - val_accuracy: 0.7481\n",
      "Epoch 12/20\n",
      "10154/10154 [==============================] - 63s 6ms/step - loss: 2.3420 - accuracy: 0.7483 - val_loss: 2.9898 - val_accuracy: 0.7481\n",
      "Epoch 13/20\n",
      "10154/10154 [==============================] - 63s 6ms/step - loss: 2.3413 - accuracy: 0.7483 - val_loss: 2.9359 - val_accuracy: 0.7481\n",
      "Epoch 14/20\n",
      "10154/10154 [==============================] - 63s 6ms/step - loss: 2.3623 - accuracy: 0.7483 - val_loss: 2.9439 - val_accuracy: 0.7481\n",
      "Epoch 15/20\n",
      "10154/10154 [==============================] - 63s 6ms/step - loss: 2.3386 - accuracy: 0.7483 - val_loss: 3.0050 - val_accuracy: 0.7481\n",
      "Epoch 16/20\n",
      "10154/10154 [==============================] - 63s 6ms/step - loss: 2.3377 - accuracy: 0.7483 - val_loss: 2.9680 - val_accuracy: 0.7481\n",
      "Epoch 17/20\n",
      "10154/10154 [==============================] - 63s 6ms/step - loss: 2.3370 - accuracy: 0.7483 - val_loss: 2.9369 - val_accuracy: 0.7481\n",
      "Epoch 18/20\n",
      "10154/10154 [==============================] - 64s 6ms/step - loss: 2.3533 - accuracy: 0.7483 - val_loss: 3.0035 - val_accuracy: 0.7481\n",
      "Epoch 19/20\n",
      "10154/10154 [==============================] - 64s 6ms/step - loss: 2.3352 - accuracy: 0.7483 - val_loss: 3.0421 - val_accuracy: 0.7481\n",
      "Epoch 20/20\n",
      "10154/10154 [==============================] - 64s 6ms/step - loss: 2.3343 - accuracy: 0.7483 - val_loss: 3.0451 - val_accuracy: 0.7481\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1ce38663e80>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=[encoder_input_data, decoder_input_data], y=decoder_target_data,\n",
    "          batch_size=BATCH_SIZE, epochs=NUM_EPOCHS, validation_split=0.2) # Run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate dev data ...\n",
      "1598/1598 [==============================] - 5s 3ms/step\n",
      "dev loss, dev acc: [1.9830278556546819, 0.9960888624191284]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the dev data using `evaluate`\n",
    "print(\"Evaluate dev data ...\")\n",
    "results = model.evaluate(x=[encoder_input_data_val_dev, decoder_input_data_val_dev], y=decoder_target_data_val_dev,\n",
    "          batch_size=BATCH_SIZE)\n",
    "print(\"dev loss, dev acc:\", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good result so we try on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate on test data ...\n",
      "23633/23633 [==============================] - 86s 4ms/step\n",
      "test loss, test acc: [1.9751797968175162, 0.9993970394134521]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test data using `evaluate`\n",
    "print(\"Evaluate test data ...\")\n",
    "results = model.evaluate(x=[encoder_input_data_val, decoder_input_data_val], y=decoder_target_data_val,\n",
    "          batch_size=BATCH_SIZE)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "main.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
